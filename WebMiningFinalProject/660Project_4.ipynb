{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6d8e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interview_title</th>\n",
       "      <th>date</th>\n",
       "      <th>offer_acceptance</th>\n",
       "      <th>experience_rating</th>\n",
       "      <th>interview_rating</th>\n",
       "      <th>interview_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Customer Success Manager Interview</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>First interview completed so far, haven't been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sr. Software engineering Manager Interview</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>Accepted Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>- 30 min chat with recruiter, both decided to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Software Engineer Interview</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>Great process - I had a coding interview and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Product Manager Interview</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>Fair and reasonable. Focus on accessibility. D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Executive Assistant Interview</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>Accepted Offer</td>\n",
       "      <td>Neutral Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>Interview process was long but worth it. I bel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               interview_title       date offer_acceptance  \\\n",
       "30          Customer Success Manager Interview 2021-09-10         No Offer   \n",
       "31  Sr. Software engineering Manager Interview 2023-04-26   Accepted Offer   \n",
       "32                 Software Engineer Interview 2023-04-25         No Offer   \n",
       "33                   Product Manager Interview 2023-04-25         No Offer   \n",
       "34               Executive Assistant Interview 2023-04-25   Accepted Offer   \n",
       "\n",
       "      experience_rating   interview_rating  \\\n",
       "30  Positive Experience  Average Interview   \n",
       "31  Positive Experience  Average Interview   \n",
       "32  Positive Experience  Average Interview   \n",
       "33  Positive Experience  Average Interview   \n",
       "34   Neutral Experience  Average Interview   \n",
       "\n",
       "                                    interview_process  \n",
       "30  First interview completed so far, haven't been...  \n",
       "31  - 30 min chat with recruiter, both decided to ...  \n",
       "32  Great process - I had a coding interview and a...  \n",
       "33  Fair and reasonable. Focus on accessibility. D...  \n",
       "34  Interview process was long but worth it. I bel...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "# Load the data\n",
    "df = pd.read_json(\"output.json\")\n",
    "df.dropna(inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60238e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interview_title</th>\n",
       "      <th>date</th>\n",
       "      <th>offer_acceptance</th>\n",
       "      <th>experience_rating</th>\n",
       "      <th>interview_rating</th>\n",
       "      <th>interview_process</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Customer Success Manager Interview</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>First interview completed so far, haven't been...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sr. Software engineering Manager Interview</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>Accepted Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>- 30 min chat with recruiter, both decided to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Software Engineer Interview</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>Great process - I had a coding interview and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Product Manager Interview</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>Fair and reasonable. Focus on accessibility. D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Executive Assistant Interview</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>Accepted Offer</td>\n",
       "      <td>Neutral Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>Interview process was long but worth it. I bel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               interview_title       date offer_acceptance  \\\n",
       "30          Customer Success Manager Interview 2021-09-10         No Offer   \n",
       "31  Sr. Software engineering Manager Interview 2023-04-26   Accepted Offer   \n",
       "32                 Software Engineer Interview 2023-04-25         No Offer   \n",
       "33                   Product Manager Interview 2023-04-25         No Offer   \n",
       "34               Executive Assistant Interview 2023-04-25   Accepted Offer   \n",
       "\n",
       "      experience_rating   interview_rating  \\\n",
       "30  Positive Experience  Average Interview   \n",
       "31  Positive Experience  Average Interview   \n",
       "32  Positive Experience  Average Interview   \n",
       "33  Positive Experience  Average Interview   \n",
       "34   Neutral Experience  Average Interview   \n",
       "\n",
       "                                    interview_process  label  \n",
       "30  First interview completed so far, haven't been...      0  \n",
       "31  - 30 min chat with recruiter, both decided to ...      1  \n",
       "32  Great process - I had a coding interview and a...      0  \n",
       "33  Fair and reasonable. Focus on accessibility. D...      0  \n",
       "34  Interview process was long but worth it. I bel...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column called 'label' based on the 'received_offer' column\n",
    "df['label'] = df['offer_acceptance'].map({'Accepted Offer': 1, 'No Offer': 0, 'Declined Offer': 0})\n",
    "\n",
    "# Remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Preview the preprocessed data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d34bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['interview_process', 'experience_rating', 'interview_rating']], df['label'], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4441cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      1930\n",
      "           1       0.54      0.50      0.52       961\n",
      "\n",
      "    accuracy                           0.69      2891\n",
      "   macro avg       0.65      0.64      0.65      2891\n",
      "weighted avg       0.69      0.69      0.69      2891\n",
      "\n",
      "Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1930\n",
      "           1       0.53      0.57      0.55       961\n",
      "\n",
      "    accuracy                           0.69      2891\n",
      "   macro avg       0.65      0.66      0.66      2891\n",
      "weighted avg       0.70      0.69      0.69      2891\n",
      "\n",
      "Linear SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      1930\n",
      "           1       0.55      0.49      0.52       961\n",
      "\n",
      "    accuracy                           0.70      2891\n",
      "   macro avg       0.66      0.65      0.65      2891\n",
      "weighted avg       0.69      0.70      0.70      2891\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80      1930\n",
      "           1       0.62      0.10      0.18       961\n",
      "\n",
      "    accuracy                           0.68      2891\n",
      "   macro avg       0.65      0.54      0.49      2891\n",
      "weighted avg       0.66      0.68      0.59      2891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the models to try\n",
    "models = [\n",
    "    ('Logistic Regression', Pipeline([('vectorizer', CountVectorizer()), ('classifier', LogisticRegression())])),\n",
    "    ('Naive Bayes', Pipeline([('vectorizer', CountVectorizer()), ('classifier', MultinomialNB())])),\n",
    "    ('Linear SVM', Pipeline([('vectorizer', TfidfVectorizer()), ('classifier', LinearSVC())])),\n",
    "    ('Random Forest', Pipeline([('vectorizer', TfidfVectorizer()), ('classifier', RandomForestClassifier())]))\n",
    "]\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    model.fit(X_train['interview_process'], y_train)\n",
    "    y_pred = model.predict(X_test['interview_process'])\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48069c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 0.1, 'vectorizer__ngram_range': (1, 1)}\n",
      "0.6956829215178624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80      1930\n",
      "           1       0.61      0.37      0.46       961\n",
      "\n",
      "    accuracy                           0.71      2891\n",
      "   macro avg       0.67      0.63      0.63      2891\n",
      "weighted avg       0.69      0.71      0.69      2891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'classifier__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid\n",
    "grid_search = GridSearchCV(models[2][1], param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train['interview_process'], y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# Test the final model on the testing set\n",
    "y_pred = grid_search.predict(X_test['interview_process'])\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e4da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9697b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b0a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da02b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2388ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271160b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b31a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ca9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9dd377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18894a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33fead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c50c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f972ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
