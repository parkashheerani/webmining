{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb88513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe/data#\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.stats import fisher_exact as FE\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1ae604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function that loads a lexicon of positive words to a set and returns the set\n",
    "def loadLexicon(fname):    \n",
    "    newLex=set()    \n",
    "    lex_conn=open(fname)    #add every word in the file to the set    \n",
    "    for line in lex_conn:        \n",
    "        newLex.add(line.strip())# remember to strip to remove the lin-change character   \n",
    "    lex_conn.close()\n",
    "    return newLex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4dfaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#compute distance between 2 reviews based on their sentiment\n",
    "def senti_dist(r1,r2,posLex,negLex):\n",
    "    \n",
    "    pos_count1,pos_count2,neg_count1,neg_count2=0,0,0,0#positive and negative counts for the 2 reviews\n",
    "\n",
    "    for term in r1:#for each term in r1\n",
    "        if term in posLex:pos_count1+=1\n",
    "        elif term in negLex:neg_count1+=1\n",
    " \n",
    "    for term in r2:#for each term in r2\n",
    "        if term in posLex:pos_count2+=1\n",
    "        elif term in negLex:neg_count2+=1\n",
    "    \n",
    "    #compute the sentiment score for r1 and r2\n",
    "    sent_score1=(pos_count1-neg_count1)/(pos_count1+neg_count1+1)\n",
    "    sent_score2=(pos_count2-neg_count2)/(pos_count2+neg_count2+1)\n",
    "    \n",
    "    sent_dist=abs(sent_score1-sent_score2)/2 # combine the 2 scores to compute their senti distance\n",
    "    \n",
    "    return sent_dist\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc735228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(review_file):\n",
    "    \n",
    "    f=open(review_file)\n",
    "    f.readline()#skip header line\n",
    "\n",
    "    reviews=[] #review texts\n",
    "    scores=[] #score texts\n",
    "\n",
    "    reader=csv.reader(f)\n",
    "    for review,score in reader:# for each review\n",
    "        reviews.append(review)\n",
    "        scores.append(float(score))\n",
    "        \n",
    "    \n",
    "    f.close()\n",
    "    return reviews,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87812521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dist_matrix(reviews):\n",
    "\n",
    "    #load the positive and negative lexicons into sets    \n",
    "    posLex=loadLexicon('positive-words.txt')\n",
    "    negLex=loadLexicon('negative-words.txt')\n",
    "    \n",
    "    N=len(reviews)\n",
    "\n",
    "    #square distance matrix full of zeros\n",
    "    sdist=numpy.zeros(shape=(N,N))\n",
    "\n",
    "    terms_per_review=[]\n",
    "\n",
    "    for i in range(N):# for each review\n",
    "        if i%50==0: print(i,'reviews loaded')\n",
    "        terms1=word_tokenize(reviews[i].lower()) # tokenize the first review\n",
    "        terms_per_review.append(terms1)\n",
    "        for j in range(i+1,N):#for each other  review\n",
    "\n",
    "            terms2=word_tokenize(reviews[j].lower()) # tokenize the second review    \n",
    "\n",
    "            sdist[i][j]=senti_dist(terms1,terms2,posLex,negLex) # compute the distance\n",
    "            sdist[j][i]=sdist[i][j] # distance is symmetric\n",
    " \n",
    "    return sdist, terms_per_review\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad954b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform the clustering step\n",
    "\"\"\"\n",
    "def get_clusters(reviews_file):\n",
    "\n",
    "    reviews,scores=load_reviews(reviews_file)\n",
    "\n",
    "    sdist,terms_per_review=create_dist_matrix(reviews)\n",
    "\n",
    "    #cluster the reviews based on distance\n",
    "    clustering = AgglomerativeClustering(n_clusters=2,affinity='precomputed',linkage='average').fit(sdist)\n",
    "\n",
    "    return clustering,scores,terms_per_review\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddee3aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews loaded\n",
      "50 reviews loaded\n",
      "100 reviews loaded\n",
      "150 reviews loaded\n",
      "200 reviews loaded\n",
      "250 reviews loaded\n",
      "300 reviews loaded\n",
      "350 reviews loaded\n",
      "400 reviews loaded\n",
      "450 reviews loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parkashheerani/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:983: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER 0: 6.39090909090909\n",
      "CLUSTER 1: 8.375064267352185\n",
      "[1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "clustering,scores,terms_per_review = get_clusters('reviews.csv')\n",
    "\n",
    "#compute the average review score for cluster0    \n",
    "cluster0_scores=[]\n",
    "for i in range(len(scores)):\n",
    "    if clustering.labels_[i]==0:\n",
    "        cluster0_scores.append(scores[i])\n",
    "print('CLUSTER 0:',numpy.mean(cluster0_scores))        \n",
    "\n",
    "#compute the average review score for cluster1\n",
    "cluster1_scores=[]\n",
    "for i in range(len(scores)):\n",
    "    if clustering.labels_[i]==1:\n",
    "        cluster1_scores.append(scores[i])\n",
    "print('CLUSTER 1:',numpy.mean(cluster1_scores))        \n",
    "\n",
    "print(clustering.labels_)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39821bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Look for characteristic terms for each of the 2 clusters using the fisher test:\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.fisher_exact.html\n",
    "\"\"\"\n",
    "\n",
    "def find_key_terms(clustering,terms_per_review):\n",
    "\n",
    "    cluster0_term_freq={}\n",
    "    cluster1_term_freq={}\n",
    "    allterms=set()\n",
    "    N0,N1=0,0 # total cumulative frequency of all terms in each cluster\n",
    "\n",
    "    for i in range(len(clustering.labels_)): # for each review\n",
    "        if clustering.labels_[i]==0:\n",
    "            for term in terms_per_review[i]:\n",
    "                cluster0_term_freq[term]=cluster0_term_freq.get(term,0)+1\n",
    "                allterms.add(term)\n",
    "                N0+=1\n",
    "        else:\n",
    "            for term in terms_per_review[i]:\n",
    "                cluster1_term_freq[term]=cluster1_term_freq.get(term,0)+1\n",
    "                allterms.add(term)\n",
    "                N1+=1\n",
    "\n",
    "\n",
    "    cluster0_distintive_terms=[]\n",
    "    cluster1_distintive_terms=[]\n",
    "\n",
    "    for term in allterms:\n",
    "        freq0=cluster0_term_freq.get(term,0)\n",
    "        freq1=cluster1_term_freq.get(term,0)\n",
    "\n",
    "        score,pval=FE([[freq0,freq1],[N0-freq0,N1-freq1]])\n",
    "\n",
    "        if pval<=0.01:\n",
    "            ratio0=freq0/N0\n",
    "            ratio1=freq1/N1\n",
    "\n",
    "            if ratio0>ratio1:\n",
    "                cluster0_distintive_terms.append(term)\n",
    "            else:\n",
    "                cluster1_distintive_terms.append(term)\n",
    "\n",
    "    print('CLUSTER 0 DISTINCTIVE TERMS:')\n",
    "    print(cluster0_distintive_terms)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print('CLUSTER 1 DISTINCTIVE TERMS:')\n",
    "    print(cluster1_distintive_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aecddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169c4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER 0 DISTINCTIVE TERMS:\n",
      "['wireing', 'running', 'smell', 'dangerous', 'disaster', 'bad', '30', 'happened', 'c', 'terrible', 'what', 'electric', 'machine', 'cold', 'second', 'water', 'no', 'horrible', 'lamp', 'noisy', 'had', 'cleaning', 'broken', 'door', 'dirty', 'manager', 'impractical', 'worst', 'came', 'nothing', 'management', 'leaking', 'poor', 'service', 'weird']\n",
      "\n",
      "CLUSTER 1 DISTINCTIVE TERMS:\n",
      "['hotel', 'friendly', 'beautiful', 'centre', 'helpful', 'comfy', 'well', 'bit', 'lovely', 'london', 'great', 'easy']\n"
     ]
    }
   ],
   "source": [
    "find_key_terms(clustering,terms_per_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b3931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff61f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e088c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
